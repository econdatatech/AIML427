{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 To reproduce the data wrangling steps one has to download the orgiginal date from https://os.unil.cloud.switch.ch/fma/fma_metadata.zip, unzip it and place the csv files contained in the zip file in the same directory as the ipynb python source file which is located on GitHub: https://github.com/econdatatech/AIML427/blob/main/Assignement%203%20AIML%20427.ipynb\
\
One has to then run the cells in the jupyter notebook file. One can also skip the data wrangling steps and start with the modelling part which will download the results form the data wrangling steps from Github: https://github.com/econdatatech/AIML427/blob/main/mfa_wrangled.bz2\
\
Due to the size of the ensemble models in terms of number of decision trees, there was not sensible way to turn them into a graphical or string representation.\
That said, the models have been stores in the pickle format and put on github:\
\
No pre-processing: https://github.com/econdatatech/AIML427/blob/main/modellg.pkl\
Scaled features: https://github.com/econdatatech/AIML427/blob/main/modellgsc.pkl\
No pre-processing: https://github.com/econdatatech/AIML427/blob/main/modellgpca.pkl\
}