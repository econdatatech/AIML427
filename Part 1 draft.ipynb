{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtj90seuLXVSr7V434alp3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/econdatatech/AIML427/blob/main/Part%201%20draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run below commands in google colab\n",
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark3.0.0\n",
        "!wget -q http://apache.osuosl.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# unzip it\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# install findspark \n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOugIQ5jUrD_",
        "outputId": "410269e1-70c5-48e0-8ef3-d79709a7fc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.0.0-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "vwJn4BrTlcFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall -y pyspark\n",
        "!pip3 install pyspark==3.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA80x85-Uxa_",
        "outputId": "15e7d594-3c2c-4bc2-da7a-c47bc49dd981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyspark 3.0.2\n",
            "Uninstalling pyspark-3.0.2:\n",
            "  Successfully uninstalled pyspark-3.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.0.2\n",
            "  Using cached pyspark-3.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.0.2) (0.10.9)\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Test the spark\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDDyiph7oRhU",
        "outputId": "e83a6d94-9362-4d21-bdb3-6aab33bc74f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
            "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "#amended from https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Load the data stored in csv format as a DataFrame.\n",
        "data = spark.read.load(\"kdd.data\",\n",
        "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"false\").toDF('duration', \n",
        "                      'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "                      'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
        "                      'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', \n",
        "                      'is_host_login', 'is_guest_login','count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n",
        "                      'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n",
        "                      'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                      'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "                      'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate','label')\n",
        "\n",
        "assembler = VectorAssembler().setInputCols(['duration', \n",
        "                      'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "                      'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
        "                      'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', \n",
        "                      'is_host_login', 'is_guest_login','count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n",
        "                      'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n",
        "                      'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                      'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "                      'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']).setOutputCol('features')\n",
        "\n",
        "data=assembler.transform(data)\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
        "# Automatically identify categorical features, and index them.\n",
        "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "#featureIndexer = [VectorIndexer(inputCol=column, outputCol=column+\"_index\", maxCategories=4).fit(data) for column in list(set(data.columns[:-1])) ]\n",
        "featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3],2342)\n",
        "\n",
        "# Train a DecisionTree model.\n",
        "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexers and tree in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions_train = model.transform(trainingData)\n",
        "\n",
        "predictions_test = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "# predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy_train = evaluator.evaluate(predictions_train)\n",
        "print(\"Train accuracy = %g \" % (accuracy_train))\n",
        "\n",
        "accuracy_test = evaluator.evaluate(predictions_test)\n",
        "print(\"Test accuracy = %g \" % (accuracy_test))\n",
        "\n",
        "\n",
        "#treeModel = model.stages[2]\n",
        "# summary only\n",
        "#print(treeModel)\n",
        "\n",
        "\n",
        "Report the training and test results including the max, min,\n",
        "average accuracy and the standard deviation obtained from the 10 runs,\n",
        "and the running time of each program."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYiJNFMdoZYL",
        "outputId": "51d9d11e-bbee-4ab8-b014-986e5aa9d050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy = 0.943957 \n",
            "Test accuracy = 0.941803 \n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_5325828822a8, depth=5, numNodes=47, numClasses=2, numFeatures=41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eob5g55kl6IR",
        "outputId": "c1870586-e2d8-47b3-d627-886538b1147c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+----+----+-----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+--------------------+\n",
            "|fea1|fea2|fea3|fea4|fea5| fea6|fea7|fea8|fea9|fea10|fea11|fea12|fea13|fea14|fea15|fea16|fea17|fea18|fea19|fea20|fea21|fea22|fea23|fea24|fea25|fea26|fea27|fea28|fea29|fea30|fea31|fea32|fea33|fea34|fea35|fea36|fea37|fea38|fea39|fea40|fea41|  label|            features|\n",
            "+----+----+----+----+----+-----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+--------------------+\n",
            "|   0|   0|  17|   9| 491|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    2|    2|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  150|   25| 0.17| 0.03| 0.17|  0.0|  0.0|  0.0| 0.05|  0.0| normal|(41,[2,3,4,22,23,...|\n",
            "|   0|   1|  42|   9| 146|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|   13|    1|  0.0|  0.0|  0.0|  0.0| 0.08| 0.15|  0.0|  255|    1|  0.0|  0.6| 0.88|  0.0|  0.0|  0.0|  0.0|  0.0| normal|(41,[1,2,3,4,22,2...|\n",
            "|   0|   0|  47|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  123|    6|  1.0|  1.0|  0.0|  0.0| 0.05| 0.07|  0.0|  255|   26|  0.1| 0.05|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  21|   9| 232| 8153|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    5|    5|  0.2|  0.2|  0.0|  0.0|  1.0|  0.0|  0.0|   30|  255|  1.0|  0.0| 0.03| 0.04| 0.03| 0.01|  0.0| 0.01| normal|(41,[2,3,4,5,11,2...|\n",
            "|   0|   0|  21|   9| 199|  420|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|   30|   32|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0| 0.09|  255|  255|  1.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0| normal|(41,[2,3,4,5,11,2...|\n",
            "|   0|   0|  47|   1|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  121|   19|  0.0|  0.0|  1.0|  1.0| 0.16| 0.06|  0.0|  255|   19| 0.07| 0.07|  0.0|  0.0|  0.0|  0.0|  1.0|  1.0|anomaly|(41,[2,3,22,23,26...|\n",
            "|   0|   0|  47|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  166|    9|  1.0|  1.0|  0.0|  0.0| 0.05| 0.06|  0.0|  255|    9| 0.04| 0.05|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  47|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  117|   16|  1.0|  1.0|  0.0|  0.0| 0.14| 0.06|  0.0|  255|   15| 0.06| 0.07|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  49|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  270|   23|  1.0|  1.0|  0.0|  0.0| 0.09| 0.05|  0.0|  255|   23| 0.09| 0.05|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  47|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  133|    8|  1.0|  1.0|  0.0|  0.0| 0.06| 0.06|  0.0|  255|   13| 0.05| 0.06|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  47|   1|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  205|   12|  0.0|  0.0|  1.0|  1.0| 0.06| 0.06|  0.0|  255|   12| 0.05| 0.07|  0.0|  0.0|  0.0|  0.0|  1.0|  1.0|anomaly|(41,[2,3,22,23,26...|\n",
            "|   0|   0|  47|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  199|    3|  1.0|  1.0|  0.0|  0.0| 0.02| 0.06|  0.0|  255|   13| 0.05| 0.07|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  21|   9| 287| 2251|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    3|    7|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0| 0.43|    8|  219|  1.0|  0.0| 0.12| 0.03|  0.0|  0.0|  0.0|  0.0| normal|(41,[2,3,4,5,11,2...|\n",
            "|   0|   0|  17|   9| 334|    0|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    2|    2|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|    2|   20|  1.0|  0.0|  1.0|  0.2|  0.0|  0.0|  0.0|  0.0|anomaly|(41,[2,3,4,11,22,...|\n",
            "|   0|   0|  34|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|  233|    1|  1.0|  1.0|  0.0|  0.0|  0.0| 0.06|  0.0|  255|    1|  0.0| 0.07|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  36|   5|   0|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|   96|   16|  1.0|  1.0|  0.0|  0.0| 0.17| 0.05|  0.0|  255|    2| 0.01| 0.06|  0.0|  0.0|  1.0|  1.0|  0.0|  0.0|anomaly|(41,[2,3,22,23,24...|\n",
            "|   0|   0|  21|   9| 300|13788|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    8|    9|  0.0| 0.11|  0.0|  0.0|  1.0|  0.0| 0.22|   91|  255|  1.0|  0.0| 0.01| 0.02|  0.0|  0.0|  0.0|  0.0| normal|(41,[2,3,4,5,11,2...|\n",
            "|   0|   2|  11|   9|  18|    0|   0|   0|   0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    1|    1|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|    1|   16|  1.0|  0.0|  1.0|  1.0|  0.0|  0.0|  0.0|  0.0|anomaly|(41,[1,2,3,4,22,2...|\n",
            "|   0|   0|  21|   9| 233|  616|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    3|    3|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|   66|  255|  1.0|  0.0| 0.02| 0.03|  0.0|  0.0| 0.02|  0.0| normal|(41,[2,3,4,5,11,2...|\n",
            "|   0|   0|  21|   9| 343| 1178|   0|   0|   0|    0|    0|    1|    0|    0|    0|    0|    0|    0|    0|    0|    0|    0|    9|   10|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.2|  157|  255|  1.0|  0.0| 0.01| 0.04|  0.0|  0.0|  0.0|  0.0| normal|(41,[2,3,4,5,11,2...|\n",
            "+----+----+----+----+----+-----+----+----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}