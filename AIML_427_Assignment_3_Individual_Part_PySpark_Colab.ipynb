{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML 427 Assignment 3 Individual Part PySpark Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jRV1v4lyIWE15jaZxmcCGy8N0Uq19_y7",
      "authorship_tag": "ABX9TyMerR1tniaySVMjlpARN/xV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/econdatatech/AIML427/blob/main/AIML_427_Assignment_3_Individual_Part_PySpark_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run below commands in google colab\n",
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark3.0.0\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# unzip it\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "# install findspark \n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "qOugIQ5jUrD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "vwJn4BrTlcFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall -y pyspark\n",
        "!pip3 install pyspark==3.0.2"
      ],
      "metadata": {
        "id": "CA80x85-Uxa_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "f3cda677-f4ae-44b1-fd74-8b04de3dc6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyspark 3.0.2\n",
            "Uninstalling pyspark-3.0.2:\n",
            "  Successfully uninstalled pyspark-3.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.0.2\n",
            "  Using cached pyspark-3.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.0.2) (0.10.9)\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "ZDDyiph7oRhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from operator import add\n",
        "import time\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.sql.functions import when, lit\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.mllib.util import MLUtils\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml.feature import PCA\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "PTVJH6hwI9Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_skip_rows = 3\n",
        "row_rdd = spark.sparkContext.textFile('features.csv').zipWithIndex().filter(lambda row: row[1] >= n_skip_rows).map(lambda row: row[0])\n",
        "\n",
        "cols = pd.read_csv('features.csv',nrows=5,header=[0,1,2])\n",
        "cols.columns=['_'.join(col).strip() for col in cols.columns.values]\n",
        "cols.rename(columns={\"feature_statistics_number\": 'track_id'},inplace=True)\n",
        "\n",
        "features = spark.read.csv(row_rdd, header ='true',inferSchema='true').toDF(*cols.columns)\n",
        "\n",
        "trackspd = pd.read_csv('tracks.csv',skiprows=[1,2],usecols=['Unnamed: 0','track.7']).rename(columns={'Unnamed: 0':'track_id',\"track.7\": \"Genre\"})\n",
        "mySchema = StructType([StructField(\"track_id\", IntegerType(), True),StructField(\"Genre\", StringType(), True)])\n",
        "tracks = spark.createDataFrame(trackspd,schema=mySchema)\n"
      ],
      "metadata": {
        "id": "JwZjWUSJG62u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below cell can download pre-wrangled data from github (as a fallback solution)"
      ],
      "metadata": {
        "id": "CrurjNvBj2Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fall back in case the above doesn't work\n",
        "#!wget -O mfa_wrangled.bz2 https://github.com/econdatatech/AIML427/blob/main/mfa_wrangled.bz2?raw=true\n",
        "#data = spark.read.option(\"sep\", \",\").csv(\"mfa_wrangled.bz2\",  header ='true',inferSchema='true')\n",
        "#new_cols=(column.replace('.', '_') for column in data.columns)\n",
        "#data = data.toDF(*new_cols)"
      ],
      "metadata": {
        "id": "KGiN9NFupNTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = features.join(tracks,['track_id'],how='inner')\n",
        "#data.show()\n",
        "#data.groupby(['Genre']).count().sort('count',ascending=False).show()\n",
        "data=data.filter(data['Genre'].isin(['Rock','Experimental']))\n",
        "data = data.withColumn('label', when(data.Genre=='Rock', lit('1')).otherwise('0'))\n",
        "data=data.drop('Genre').drop('track_id')\n",
        "#data.count()"
      ],
      "metadata": {
        "id": "poUIiVcDq6oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler().setInputCols(data.columns[:-1]).setOutputCol('features')\n",
        "data=assembler.transform(data)\n",
        "labelIndexer = StringIndexer(inputCol='label', outputCol=\"indexedLabel\").fit(data)\n",
        "featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
      ],
      "metadata": {
        "id": "V-y3e7qbvZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "seed=23\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3],seed)\n",
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions_train = model.transform(trainingData)\n",
        "\n",
        "predictions_test = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions_test.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy_train = evaluator.evaluate(predictions_train)\n",
        "accuracy_test = evaluator.evaluate(predictions_test)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "columns = ['ValueType', 'Value']\n",
        "vals = [\n",
        "     ('Train accuracy', (accuracy_train)),\n",
        "     ('Test accuracy', (accuracy_test)),\n",
        "    ('Run time', (end-start)/60)\n",
        "\n",
        "]\n",
        "dfnor = spark.createDataFrame(vals, columns)\n",
        "\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge9D6vZR06vX",
        "outputId": "f06fbd7d-4154-4754-f2c6-679346e4290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------------------+\n",
            "|prediction|indexedLabel|            features|\n",
            "+----------+------------+--------------------+\n",
            "|       1.0|         1.0|[-1.5479236841,-1...|\n",
            "|       0.0|         0.0|[-1.1817407608,0....|\n",
            "|       1.0|         1.0|[-0.91913110018,-...|\n",
            "|       1.0|         0.0|[-0.85557812452,-...|\n",
            "|       0.0|         0.0|[-0.79573595524,-...|\n",
            "+----------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "GBTClassificationModel: uid = GBTClassifier_c61a14101545, numTrees=20, numClasses=2, numFeatures=518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfnor.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQJm-tMQ8wmK",
        "outputId": "b7b4077e-aeef-464c-e3fd-98c0541ff6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|     ValueType|             Value|\n",
            "+--------------+------------------+\n",
            "|Train accuracy|0.8683315070073245|\n",
            "| Test accuracy|0.8304925513353912|\n",
            "|      Run time|15.423114673296611|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard Scale\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "scaler = StandardScaler(withMean=True, withStd=True,inputCol=\"features\", outputCol=\"normFeatures\")\n",
        "scaly = scaler.fit(trainingData)\n",
        "\n",
        "data = scaly.transform(data)\n",
        "featureIndexer =VectorIndexer(inputCol=\"normFeatures\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3],seed)\n",
        "\n",
        "\n",
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions_train = model.transform(trainingData)\n",
        "\n",
        "predictions_test = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions_test.select(\"prediction\", \"indexedLabel\", \"normFeatures\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy_train = evaluator.evaluate(predictions_train)\n",
        "accuracy_test = evaluator.evaluate(predictions_test)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "columns = ['ValueType', 'Value']\n",
        "vals = [\n",
        "     ('Train accuracy', (accuracy_train)),\n",
        "     ('Test accuracy', (accuracy_test)),\n",
        "    ('Run time', (end-start)/60)\n",
        "\n",
        "]\n",
        "dfsc = spark.createDataFrame(vals, columns)\n",
        "\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only"
      ],
      "metadata": {
        "id": "gelMb_7BI8FF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746dba0d-8023-44e7-b4d3-3fc12416cb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------------------+\n",
            "|prediction|indexedLabel|        normFeatures|\n",
            "+----------+------------+--------------------+\n",
            "|       1.0|         1.0|[-0.8660555467494...|\n",
            "|       0.0|         0.0|[-0.6990745307516...|\n",
            "|       1.0|         1.0|[-0.5793233759299...|\n",
            "|       1.0|         0.0|[-0.5503429408245...|\n",
            "|       0.0|         0.0|[-0.5230546496726...|\n",
            "+----------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "GBTClassificationModel: uid = GBTClassifier_2417f898e2ca, numTrees=20, numClasses=2, numFeatures=518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfsc.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYUAJ9y5CZvA",
        "outputId": "37d0f886-e079-4c54-eab7-644c74dce03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|     ValueType|             Value|\n",
            "+--------------+------------------+\n",
            "|Train accuracy|0.8668896706845839|\n",
            "| Test accuracy|0.8255267749295396|\n",
            "|      Run time| 17.32752676407496|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "pca = PCA(k=518,inputCol=\"normFeatures\", outputCol=\"pca\")\n",
        "model = pca.fit(trainingData)\n",
        "\n",
        "data = model.transform(data)\n"
      ],
      "metadata": {
        "id": "yMf14wASJyw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featureIndexer =VectorIndexer(inputCol=\"pca\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3],seed)\n",
        "\n",
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions_train = model.transform(trainingData)\n",
        "\n",
        "predictions_test = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions_test.select(\"prediction\", \"indexedLabel\", \"pca\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy_train = evaluator.evaluate(predictions_train)\n",
        "accuracy_test = evaluator.evaluate(predictions_test)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "columns = ['ValueType', 'Value']\n",
        "vals = [\n",
        "     ('Train accuracy', (accuracy_train)),\n",
        "     ('Test accuracy', (accuracy_test)),\n",
        "    ('Run time', (end-start)/60)\n",
        "\n",
        "]\n",
        "dfpca = spark.createDataFrame(vals, columns)\n",
        "\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz2lq5oeKr8c",
        "outputId": "80b9977b-0288-4f16-933b-8d6ca2bde217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------------------+\n",
            "|prediction|indexedLabel|                 pca|\n",
            "+----------+------------+--------------------+\n",
            "|       1.0|         1.0|[8.35891430112388...|\n",
            "|       0.0|         0.0|[2.18806224797266...|\n",
            "|       1.0|         1.0|[5.93260669459259...|\n",
            "|       0.0|         0.0|[6.32561157549543...|\n",
            "|       0.0|         0.0|[-1.4067773142646...|\n",
            "+----------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "GBTClassificationModel: uid = GBTClassifier_b08a96e27f33, numTrees=20, numClasses=2, numFeatures=518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfpca.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miWii2EyLRas",
        "outputId": "d725e35a-0cb5-49b2-8cc6-e71c6d35f9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|     ValueType|             Value|\n",
            "+--------------+------------------+\n",
            "|Train accuracy|0.8486648595651421|\n",
            "| Test accuracy| 0.807408401556838|\n",
            "|      Run time|  20.3068524201711|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-S8Qnl_7wQ0",
        "outputId": "ff7863c2-9d09-4a7d-b27b-47fd60ab3daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24790"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}